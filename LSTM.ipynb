{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mukul-rathi/workshop-deep-learning/blob/master/LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "S3NOjcDJun6V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM \n",
        "\n",
        "This is the notebook accompanying the LSTM workshop. \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8_IsUj_aulCK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#import the keras functions\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import  Input, Embedding, Dense, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from  keras.utils import to_categorical as OneHotEncode\n",
        "\n",
        "#import the IMDB dataset\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zrqO7kqGvCNU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now to import the data:"
      ]
    },
    {
      "metadata": {
        "id": "h82QS2d_vA_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "maxlen = 200\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "\n",
        "#Preprocess the data so the same length (padding as necessary)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2QEMfqFvajF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initLSTM():\n",
        "  rnn = Sequential()\n",
        "  rnn.add(Embedding(max_features, 128)) #word embeddings for each of words in input\n",
        "  rnn.add(LSTM(128, recurrent_dropout = 0.2)) #LSTM cell\n",
        "  rnn.add(Dense(1, activation='sigmoid')) #output prediction\n",
        "  return rnn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDx9oKxFvNyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rnn = initLSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yU_rceWVvgqJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next to compile and train the model:\n"
      ]
    },
    {
      "metadata": {
        "id": "-Ll4K56DvIYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1bf140e0-a3ca-4c18-a8d2-3674a52c3fd4"
      },
      "cell_type": "code",
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "rnn.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "rnn.fit(x_train, y_train,\n",
        "          batch_size=512,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 36s 1ms/step - loss: 0.5586 - acc: 0.7172 - val_loss: 0.3666 - val_acc: 0.8432\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 35s 1ms/step - loss: 0.3299 - acc: 0.8665 - val_loss: 0.3566 - val_acc: 0.8467\n",
            "Epoch 3/5\n",
            "25000/25000 [==============================] - 35s 1ms/step - loss: 0.2333 - acc: 0.9136 - val_loss: 0.3490 - val_acc: 0.8512\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 35s 1ms/step - loss: 0.2004 - acc: 0.9274 - val_loss: 0.3897 - val_acc: 0.8530\n",
            "Epoch 5/5\n",
            "25000/25000 [==============================] - 35s 1ms/step - loss: 0.1629 - acc: 0.9420 - val_loss: 0.4521 - val_acc: 0.7975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f859b8faef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "wt6nprr1wBml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8e2e023-4a6c-47b0-e941-0279c92de486"
      },
      "cell_type": "code",
      "source": [
        "score, acc = rnn.evaluate(x_test, y_test,\n",
        "                            batch_size=512)\n",
        "print(\"Test accuracy: \" + str(acc))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 7s 278us/step\n",
            "Test accuracy: 0.7975199996376038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOMuE1BM86I-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## See specific predictions:"
      ]
    },
    {
      "metadata": {
        "id": "hkjWBEzMxitT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#create a mapping from the index to the word\n",
        "idx_to_word = {(v+3):k for k,v in imdb.get_word_index().items()}\n",
        "idx_to_word.update({0:\"<PAD>\", 1: \"<START>\", 2: \"<UNK>\",3:\"<UNUSED>\"}) #first 3 indices are special tokens \n",
        "\n",
        "vocab_size = np.max(list(idx_to_word.keys()))\n",
        "#this is a helper function - good to debug performance of model during training\n",
        "def print_review(x):\n",
        "    text = \"\"\n",
        "    for idx in x:\n",
        "        text += idx_to_word.get(idx, \"<UNK>\") + \" \" #if word not in dictionary it is unknown\n",
        "    return text\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQ7JF_Pj82Fb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "634d1a65-61c9-4675-bdd1-5b4294a29f70"
      },
      "cell_type": "code",
      "source": [
        "#choose a random review \n",
        "review_num = np.random.randint(0,x_test.shape[0])\n",
        "review = x_test[review_num]\n",
        "review = np.reshape(review, (1, x_test.shape[1]))\n",
        "\n",
        "print(\"The predicted sentiment is: \" + str((rnn.predict(review))))\n",
        "print(print_review(review[0]))\n",
        "print(\"The actual sentiment is: \" + str(y_test[review_num]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted sentiment is: [[0.9916632]]\n",
            "the spectators look different at the same scenes when they are told first from <UNK> point of view then from one the main actors do very good and especially the growing love between the two women is convincingly developed with a first culmination in a very tender love scene between the two and finally forgiving all the evil they were ready to do and did to each other because they still love each other br br for each of her books the author sarah waters has thoroughly investigated what life was like in british 19th century while in <UNK> the velvet it was the world of the vaudeville theaters and the beginning of social movements in affinity the dreadful reality of women <UNK> and the fashionable <UNK> of spirits in she depicts the public ceremony of hanging people in london and the inhuman treatment of persons supposed or declared disturbed in <UNK> based on the reading of sources and scientific research this is very well transferred to the film so that the <UNK> scenes show a high grade of historic truth i highly recommend this film production because it offers three hours of colorful victorian atmosphere vivid emotions and suspense \n",
            "The actual sentiment is: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UOHk6bTd9mcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CmJi7tqp-LlZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}