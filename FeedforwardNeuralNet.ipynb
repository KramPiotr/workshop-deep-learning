{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeedforwardNeuralNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukul-rathi/workshop-deep-learning/blob/master/FeedforwardNeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "R9Dcw7yC_FTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feedforward Neural Networks\n",
        "\n",
        "This Jupyter notebook accompanies the blog post on Feedforward Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "0FSW41K5_FTN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we will import the dependencies - **numpy**, the python linear algebra library, **pandas** to load and preprocess the input data and **matplotlib** for visualisation purposes."
      ]
    },
    {
      "metadata": {
        "id": "w2tsb3eK_FTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_boston,load_breast_cancer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozNhjbuS_FTT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " First, the house dataset - this is the dataset we used for linear regression."
      ]
    },
    {
      "metadata": {
        "id": "XUe4J9h8BRwd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X,y = load_boston(return_X_y=True)\n",
        "#X,y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# make sure dimensions are right\n",
        "X = X.T\n",
        "y = np.reshape(y, (1,y.shape[0]))\n",
        "\n",
        "\n",
        "#normalise the data\n",
        "mean = np.mean(X, axis=1, keepdims=True)\n",
        "std = np.std(X, axis=1,keepdims = True)\n",
        "X -=mean\n",
        "X /= std\n",
        "\n",
        "\n",
        "X_train = X[:,:2*X.shape[0]//3]\n",
        "Y_train = y[:,:2*X.shape[0]//3]\n",
        "\n",
        "X_test = X[:,2*X.shape[0]//3:]\n",
        "Y_test = y[:,2*X.shape[0]//3:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pe4zmPEu_FTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating the neural network:\n",
        "\n",
        "Having preprocessed our data into matrices, it is now time to create the feedforward neural network. "
      ]
    },
    {
      "metadata": {
        "id": "sUfdUeJQ_FTd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First we need to initialise parameters: the weights and biases for each layer.\n",
        "\n",
        "The weights for layer *$l$* are stored in *$ W^{(l)}$*, a *$n_l$ x $n_{(l-1)}$* matrix, where *$n_l$* is the number of units in layer *$l$*. \n",
        "We  initialise the weights randomly from a Gaussian distribution ($\\mu=0, \\sigma =1$) to break symmetry, and multiply by 0.001 to ensure weights aren't too large.\n",
        "\n",
        "The biases for layer *$l$* are stored in *$ b^{(l)}$*, which is a *$n_l$ x 1* matrix."
      ]
    },
    {
      "metadata": {
        "id": "fQI5mNln_FTf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialise_parameters(layers_units):\n",
        "    parameters = {}            # create a dictionary containing the parameters\n",
        "    for l in range(1, len(layers_units)):\n",
        "        parameters['W' + str(l)] = 0.001* np.random.randn(layers_units[l],layers_units[l-1])\n",
        "        parameters['b' + str(l)] = np.zeros((layers_units[l],1))\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QBvP-WeS_FTi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The activation function $g(z)$ we will be using is the ReLU function $g(z) = max(0,z)$ in the hidden layers.\n",
        "\n",
        "<br> The only difference in the neural net between regression and classification is the final layer - whether we use the sigmoid function in the final layer, depending on whether we want to do regression or classification. \n",
        "\n",
        "NB: Although the ReLU function is technically non-differentiable when $z=0$, in practice we can set the derivative=0 at $z=0$."
      ]
    },
    {
      "metadata": {
        "id": "-zS22wKC_FTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "def relu(z, deriv = False):\n",
        "    if(deriv):\n",
        "        return z>0\n",
        "    else:\n",
        "        return np.multiply(z, z>0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xdw2iwNX_FTl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now write the code for the forward propagation step.\n",
        "\n",
        "In each layer $l$ , we matrix multiply the output of the previous layer $A^{(l-1)}$  by a weight matrix $W^{(l)}$ and then add a bias term $b^{(l)}$. We then take the result $Z^{(l)}$ and apply the activation function $g(z)$ to it to get the output $A^{(l)}$. $L$ = number of layers.\n",
        "The equations are thus:\n",
        "$$Z^{(l)}=W^{(l)}A^{(l-1)}$$\n",
        "$$A^{(l)}=g(Z^{(l)})$$\n"
      ]
    },
    {
      "metadata": {
        "id": "G1mGl8Ol_FTl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(X,parameters):\n",
        "    cache = {}\n",
        "    L = len(parameters)//2 #final layer\n",
        "    cache[\"A0\"] = X #ease of notation since input = layer 0\n",
        "    for l in range(1, L):\n",
        "        cache['Z' + str(l)] = np.dot(parameters['W' + str(l)],cache['A' + str(l-1)]) + parameters['b' + str(l)]\n",
        "        cache['A' + str(l)] = relu(cache['Z' + str(l)])\n",
        "    #final layer\n",
        "    cache['Z' + str(L)] = np.dot(parameters['W' + str(L)],cache['A' + str(L-1)]) + parameters['b' + str(L)]\n",
        "    cache['A' + str(L)] =cache['Z' + str(L)] \n",
        "    return cache "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwuBdFF9_FTo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we can compute the loss function - this is the objective function the neural network will aim to minimise during training:\n",
        "\n",
        "$m$ = number of training examples, $(x^{(i)},y^{(i)})$ is the $i^{th}$ training example.\n",
        "<br> For regression: \n",
        "$$ J(W^{(1)}, b^{(1)},...) = \\frac{1}{2m} \\sum_{i=1}^{m} (a^{(L) (i)} - y^{(i)})^2 $$\n",
        "\n",
        "\n",
        "For classification: \n",
        "\n",
        "$$J(W^{(1)}, b^{(1)},...) = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} y^{(i)}\\log\\left(a^{(L) (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{(L)(i)}\\right)Â $$\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "h614AF-__FTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cost_function(AL,Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = (1/(2*m))*(np.sum(np.square(AL-Y)))\n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GTMg3uoB_FTs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will code the backpropagation algorithm. This will enable us to calculate the partial derivative of the cost function with respect to each of the weights and biases in each of the layers of the network. The equations can be derived using the multivariable chain rule and are the same for both regression and classification:\n",
        "$$\\frac{\\partial \\mathcal{J} }{\\partial Z^{(L)}} = A^{(L)} - Y$$ \n",
        "\n",
        "\n",
        "$$ \\frac{\\partial \\mathcal{J} }{\\partial W^{(l)}} = \\frac{1}{m}\\frac{\\partial \\mathcal{J} }{\\partial Z^{(l)}} A^{(l-1) T} $$\n",
        "\n",
        "$$ \\frac{\\partial \\mathcal{J} }{\\partial b^{(l)}} = \\frac{1}{m} \\sum_{i = 1}^{m} \\frac{\\partial \\mathcal{J} }{\\partial Z^{(l)(i)}}$$\n",
        "\n",
        "$$ \\frac{\\partial \\mathcal{J} }{\\partial A^{(l-1)}} = W^{(l) T} \\frac{\\partial \\mathcal{J} }{\\partial Z^{(l)}} $$\n",
        "$$ \\frac{\\partial \\mathcal{J} }{\\partial Z^{(l-1)}} = \\frac{\\partial \\mathcal{J} }{\\partial A^{(l-1)}}*g^{'}(Z^{(l-1)})$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JMoNeqUU_FTt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backpropagation(cache,Y,parameters):\n",
        "    L = len(parameters)//2 \n",
        "    m = Y.shape[1]\n",
        "    grads = {}\n",
        "    grads[\"dZ\" + str(L)]= cache[\"A\" + str(L)] - Y\n",
        "    grads[\"dW\" + str(L)]= (1/m)*np.dot(grads[\"dZ\" + str(L)],cache[\"A\" + str(L-1)].T) \n",
        "    grads[\"db\" + str(L)]= (1/m)*np.sum(grads[\"dZ\" + str(L)],axis=1,keepdims=True)\n",
        "    for l in range(L-1,0,-1):\n",
        "        grads[\"dA\" + str(l)]= np.dot(parameters[\"W\" + str(l+1)].T,grads[\"dZ\" + str(l+1)])\n",
        "        grads[\"dZ\" + str(l)]= np.multiply(grads[\"dA\" + str(l)], relu(cache[\"Z\" + str(l)], deriv = True))\n",
        "        grads[\"dW\" + str(l)]= (1/m)*np.dot(grads[\"dZ\" + str(l)],cache[\"A\" + str(l-1)].T) \n",
        "        grads[\"db\" + str(l)]= (1/m)*np.sum(grads[\"dZ\" + str(l)],axis=1,keepdims=True)\n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UULYlOSA_FTv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to have an evaluation metric to see if the model is actually learning.\n",
        "\n",
        "For regression, we use Mean Squared Error."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "FtDypLdm_FTz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's combine the functions created so far to create a model and train it using  gradient descent. \n",
        "\n",
        "The update equations for the parameters are as follows:\n",
        "$$ W^{(l)} = W^{(l)} - \\alpha \\frac{\\partial \\mathcal{J} }{\\partial W^{(l)}} $$\n",
        "\n",
        "$$ b^{(l)} = b^{(l)} - \\alpha \\frac{\\partial \\mathcal{J} }{\\partial b^{(l)}} $$\n",
        "\n",
        "where $\\alpha$ is the learning rate parameter."
      ]
    },
    {
      "metadata": {
        "id": "DPXbsDfq_FTz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(X_train, Y_train,num_epochs,layers_units,learning_rate):\n",
        "    train_costs = []\n",
        "    \n",
        "    parameters = initialise_parameters(layers_units)\n",
        "    L = len(layers_units)-1 \n",
        "    for epoch in range (num_epochs):\n",
        "        #perform one cycle of forward and backward propagation to get the partial derivatives w.r.t. the weights\n",
        "        #and biases. Calculate the cost - used to monitor training\n",
        "        cache = forward_propagation(X_train,parameters)\n",
        "        cost = cost_function(cache[\"A\" + str(L)],Y_train)\n",
        "        grads = backpropagation(cache,Y_train,parameters)\n",
        "\n",
        "        #update the parameters using gradient descent\n",
        "        for l in range(1,L+1):\n",
        "            parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*grads[\"dW\" + str(l)]\n",
        "            parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*grads[\"db\" + str(l)]\n",
        "\n",
        "        #periodically output an update on the current cost and performance on the dev set for visualisation\n",
        "        train_costs.append(cost)\n",
        "        if(epoch%(num_epochs//10)==0):\n",
        "            print(\"Training the model, epoch: \" + str(epoch+1))\n",
        "            print(\"Cost after epoch \" + str((epoch)) + \": \" + str(cost))\n",
        "    print(\"Training complete!\")\n",
        "    #return the trained parameters and the visualisation metrics\n",
        "    return parameters, train_costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhvigzxs_FT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To evaluate the model, we visualise the training set error over the number of iterations. We then output the final value of the evaluation metric for training and test sets."
      ]
    },
    {
      "metadata": {
        "id": "z6Pfr4gB_FT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_model(train_costs,parameters,X_train, Y_train, X_test, Y_test):\n",
        "    #plot the graphs of training set error\n",
        "    plt.plot(np.squeeze(train_costs))\n",
        "    plt.ylabel('Cost')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.title(\"Training Set Error\")\n",
        "    plt.show()\n",
        "    L = len(parameters)//2\n",
        "    \n",
        "    #For train and test sets, perform a step of forward propagation to obtain the trained model's \n",
        "    #predictions and evaluate this\n",
        "    \n",
        "    train_cache = forward_propagation(X_train,parameters)\n",
        "    train_AL = train_cache[\"A\"+ str(L)]\n",
        "    \n",
        "    print(\"The train set MSE is: \"+str(cost_function(train_AL,Y_train)))\n",
        "        \n",
        "    test_cache = forward_propagation(X_test,parameters)\n",
        "    test_AL = test_cache[\"A\"+ str(L)]\n",
        "    \n",
        "    print(\"The test set MSE is: \"+str(cost_function(test_AL,Y_test)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLFSl4bt_FT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now can write the overall function to run the neural network - this ensures it is easy to run subsequent models by packaging all the functions into one line of code."
      ]
    },
    {
      "metadata": {
        "id": "vQwKmiqV_FT6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define the hyperparameters for the model\n",
        "num_epochs = 1500 #number of passes through the training set\n",
        "layers_units = [X.shape[0], 1] #layer 0 is the input layer\n",
        "learning_rate = 1e-4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "few8mbeH_FT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8a9001e0-e4e4-4ff2-ab67-cdb26a66a39c"
      },
      "cell_type": "code",
      "source": [
        "parameters, train_costs = train_model(X_train, Y_train ,num_epochs,layers_units,learning_rate)         "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model, epoch: 1\n",
            "Cost after epoch 0: 422.1860647701419\n",
            "Training the model, epoch: 151\n",
            "Cost after epoch 150: 407.5661762677985\n",
            "Training the model, epoch: 301\n",
            "Cost after epoch 300: 393.5607498789798\n",
            "Training the model, epoch: 451\n",
            "Cost after epoch 450: 380.1447504504729\n",
            "Training the model, epoch: 601\n",
            "Cost after epoch 600: 367.2941658166171\n",
            "Training the model, epoch: 751\n",
            "Cost after epoch 750: 354.9859639673048\n",
            "Training the model, epoch: 901\n",
            "Cost after epoch 900: 343.19805206407676\n",
            "Training the model, epoch: 1051\n",
            "Cost after epoch 1050: 331.90923722230025\n",
            "Training the model, epoch: 1201\n",
            "Cost after epoch 1200: 321.0991889811378\n",
            "Training the model, epoch: 1351\n",
            "Cost after epoch 1350: 310.74840338657725\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HxRFpsk0Kd9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "68f6327a-c472-4bbe-fa20-201826b509ab"
      },
      "cell_type": "code",
      "source": [
        "evaluate_model(train_costs,parameters,X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFnCAYAAABdOssgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8b55021588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The train set MSE is: 300.8381686161749\n",
            "The test set MSE is: 308.0581336552814\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}